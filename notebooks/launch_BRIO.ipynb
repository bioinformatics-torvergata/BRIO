{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261a9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "It is assumed that the input elements (in sys.argv[1] and sys.argv[2]) are:\n",
    ">header\n",
    "RNA sequence\n",
    "\n",
    "or\n",
    "\n",
    ">header\n",
    "RNA sequence\n",
    "Dot-Bracket structure\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "import output_generation\n",
    "\n",
    "from random import choice\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import json\n",
    "\n",
    "MIN_LEN_SEQ_FOR_STR_MOTIFS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d535049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = re.compile(\" (.+)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62e35b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search(dir_base, path_motif, path_input_seq_struct_bear, str_else_nuc, path_output, min_seq_len=3):\n",
    "    subprocess.Popen(\n",
    "        [\n",
    "            'python3', os.path.join(dir_base, 'scripts', 'search2.0.py'),\n",
    "            '--input', path_input_seq_struct_bear,\n",
    "            '--motifs', path_motif,\n",
    "            '--output', path_output,\n",
    "            '--min-seq-len', str(min_seq_len)\n",
    "        ] + ([] if str_else_nuc else ['--sequence']),\n",
    "        # To get strings\n",
    "        universal_newlines=True\n",
    "    ).wait()\n",
    "\n",
    "\n",
    "def perc_seq_motif(motif, inp_search, dic, str_else_nuc):\n",
    "    # num seq col motivo\n",
    "    major = 0\n",
    "    # num seq senza motivo\n",
    "    minor = 0\n",
    "\n",
    "    tot = 0\n",
    "    threshold = dic[motif]\n",
    "\n",
    "    f = inp_search.strip('\\n').split('\\n')\n",
    "    if str_else_nuc:\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            if len(line) > 2:\n",
    "                tot = tot + 1\n",
    "                val = float(line[3].strip('\\n'))\n",
    "                if val > threshold:\n",
    "                    major = major + 1\n",
    "    else:\n",
    "        for line in f:\n",
    "            tot = tot + 1\n",
    "            val = float(line.split('\\t')[2])\n",
    "            if val > threshold:\n",
    "                major = major + 1\n",
    "\n",
    "    if tot == 0:\n",
    "        perc = 0\n",
    "    else:\n",
    "        perc = float(major) / tot * 100\n",
    "        minor = tot - major\n",
    "\n",
    "    return perc, major, minor\n",
    "\n",
    "\n",
    "def search_motif_name(file_bench):\n",
    "    f = open(file_bench)\n",
    "    line = f.readline()\n",
    "    pssm = []\n",
    "    while line:\n",
    "        if line == \"#PSSM\\n\":\n",
    "            pssm.append(line.split())\n",
    "            while line[0:6] != \"#score\":\n",
    "                line = f.readline()\n",
    "                pssm.append(line.split())\n",
    "\n",
    "        line = f.readline()\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    m = [el[0] for el in pssm[1:-2]]\n",
    "    motif_name = ''.join(m)\n",
    "\n",
    "    return motif_name\n",
    "\n",
    "\n",
    "def process_input_rna_molecules(input_rna_molecules, dir_output):\n",
    "    missing_dotbracket_and_bear_rna_molecules = ''\n",
    "    missing_bear_rna_molecules = ''\n",
    "\n",
    "    input_rna_to_length_dict = {}\n",
    "\n",
    "    for single_rna in input_rna_molecules.strip('\\n>').split('\\n>'):\n",
    "        single_rna_list = [x.strip('\\r') for x in single_rna.split('\\n')]\n",
    "\n",
    "        single_rna_list[0] = '>' + single_rna_list[0]\n",
    "        single_rna_list[1] = single_rna_list[1].upper().replace('T', 'U')\n",
    "\n",
    "        input_rna_to_length_dict[single_rna_list[0]] = len(single_rna_list[1])\n",
    "\n",
    "        if len(single_rna_list) == 2:\n",
    "            missing_dotbracket_and_bear_rna_molecules += '\\n'.join(single_rna_list) + '\\n'\n",
    "        else:\n",
    "            missing_bear_rna_molecules += '\\n'.join(single_rna_list) + '\\n'\n",
    "\n",
    "    path_complete_input = os.path.join(dir_output, 'complete_input_with_dot_bracket_and_bear.txt')\n",
    "\n",
    "    missing_bear_rna_molecules_all = ''\n",
    "    if missing_dotbracket_and_bear_rna_molecules:\n",
    "        path_missing_dot_bracket_input = os.path.join(dir_output, 'tmp.missing_dot_bracket_input.txt')\n",
    "        with open(path_missing_dot_bracket_input, 'w') as fw:\n",
    "            fw.write(missing_dotbracket_and_bear_rna_molecules)\n",
    "\n",
    "        # Calculate dotbracket\n",
    "        missing_bear_rna_molecules_added_dot_bracket = subprocess.check_output(\n",
    "            [os.path.join(dir_base, 'scripts', 'RNAfold'), '-j 1', '--noPS', path_missing_dot_bracket_input],\n",
    "            # To get strings\n",
    "            universal_newlines=True\n",
    "        )\n",
    "\n",
    "        # Remove the energies\n",
    "        for x in missing_bear_rna_molecules_added_dot_bracket.strip('\\n>').split('\\n>'):\n",
    "            x_list = x.split('\\n')\n",
    "            x_list[2] = re.sub(r' \\((.*?)\\)', '', x_list[2])\n",
    "            missing_bear_rna_molecules_all += '>' + '\\n'.join(x_list) + '\\n'\n",
    "\n",
    "    missing_bear_rna_molecules_all += missing_bear_rna_molecules\n",
    "    if missing_bear_rna_molecules_all:\n",
    "        path_missing_bear_input = os.path.join(dir_output, 'tmp.missing_bear_input.txt')\n",
    "        with open(path_missing_bear_input, 'w') as fw:\n",
    "            fw.write(missing_bear_rna_molecules_all)\n",
    "\n",
    "        # Calculate BEAR\n",
    "        subprocess.call(\n",
    "            ['java', '-jar', os.path.join(dir_base, 'scripts', 'BearEncoder_new.jar'), path_missing_bear_input,\n",
    "             path_complete_input]\n",
    "        )\n",
    "\n",
    "    return path_complete_input, input_rna_to_length_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "940bb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = \"../\"\n",
    "\n",
    "dir_struct_motifs = os.path.join(dir_base, 'motifs_str_groups/')\n",
    "dir_nucleotide_motifs = os.path.join(dir_base, 'motifs_nuc_groups/')\n",
    "\n",
    "dir_struct_motifs_domains = os.path.join(dir_base, 'resources/dict_dom_searchMotifs_nuc.txt')\n",
    "dir_nucleotide_motifs_domains = os.path.join(dir_base, 'resources/dict_dom_searchMotifs_str.txt')\n",
    "\n",
    "search_struct_motifs = 'str'  # else ''\n",
    "search_seq_motifs = 'nuc'  # else ''\n",
    "\n",
    "species_list = \"hg19\\n\" #sys.argv[4].split(',')\n",
    "experiments_list = \"PAR\\n\" #sys.argv[5].split(',')\n",
    "\n",
    "user_email = \"\"#sys.argv[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d0b987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "background=\"\"#\">chr1:149783661-149783992(-)\\nAGCACUUUGCGAGUCUUCAUUUGCAUACGGGCUCUAUAAGUAGCGCCAAAAAAAA\\n>chr2:149783661-149783992(-)\\nAAAAAAAAAAAAAAAAACUUCAUUUGCAUACGGGCUCUAUAAGUAGCGCCAAAAAAAA\\n\"\n",
    "is_there_a_background = background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76cd5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"user\\n\"\n",
    "\n",
    "dir_user = os.path.join(dir_base, 'public/results', user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c901bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory preparation\n",
    "if not os.path.exists(dir_user):\n",
    "    os.makedirs(dir_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549c9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=\">chr1:149783661-149783992(-)\\nAGCACUUUGCGAGUCUUCAUUUGCAUACGGGCUCUAUAAGUAGCGCCAAAAAAAA\\n\"\n",
    "\n",
    "path_complete_input_rna_molecules, input_rna_to_length_dict = process_input_rna_molecules(seq, dir_user)\n",
    "\n",
    "path_complete_input_rna_molecules_background = ''\n",
    "if is_there_a_background:\n",
    "    if not os.path.exists(os.path.join(dir_user, 'background')):\n",
    "        os.makedirs(os.path.join(dir_user, 'background'))\n",
    "\n",
    "    path_complete_input_rna_molecules_background, _ = process_input_rna_molecules(\n",
    "        background, os.path.join(dir_user, 'background')\n",
    "    )\n",
    "\n",
    "path_str_or_nuc_motif_to_search_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42493bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1:149783661-149783992(-)\n",
      "Remove ../public/results/user\n",
      "/tmp.missing_bear_input.txt\n",
      "Remove ../public/results/user\n",
      "/tmp.missing_dot_bracket_input.txt\n"
     ]
    }
   ],
   "source": [
    "# Check if there are sequences available for searching structural motifs\n",
    "for path_complete_input_rna_molecules_xxx in [path_complete_input_rna_molecules,\n",
    "                                              path_complete_input_rna_molecules_background]:\n",
    "    num_valid_seq_for_str_motifs = 0\n",
    "\n",
    "    # The background path can be empty\n",
    "    if path_complete_input_rna_molecules_xxx:\n",
    "        with open(path_complete_input_rna_molecules_xxx) as f:\n",
    "            for line in f:\n",
    "                if line.startswith('>'):\n",
    "                    # header = line.split()\n",
    "                    seq = f.readline()\n",
    "                    # print(header, len(seq))\n",
    "                    if len(seq) >= MIN_LEN_SEQ_FOR_STR_MOTIFS:\n",
    "                        num_valid_seq_for_str_motifs += 1\n",
    "                    f.readline()\n",
    "                    f.readline()\n",
    "\n",
    "        if num_valid_seq_for_str_motifs == 0:\n",
    "            # Disable it\n",
    "            search_struct_motifs = ''\n",
    "            break\n",
    "\n",
    "for str_or_nuc, dir_str_or_nuc_motifs in zip(\n",
    "        [search_struct_motifs, search_seq_motifs],\n",
    "        [dir_struct_motifs, dir_nucleotide_motifs],\n",
    "):\n",
    "    if str_or_nuc:\n",
    "        path_str_or_nuc_motif_to_search_dict[str_or_nuc] = []\n",
    "\n",
    "        for filename_motif in [x for x in os.listdir(dir_str_or_nuc_motifs) if x.startswith('motifs_')]:\n",
    "            experiment, specie = filename_motif.split('_')[1:3]\n",
    "\n",
    "            if re.findall(r\"(?=(\" + '|'.join(species_list) + r\"))\", specie) and \\\n",
    "                    re.findall(r\"(?=(\" + '|'.join(experiments_list) + r\"))\", experiment):\n",
    "                path_str_or_nuc_motif_to_search_dict[str_or_nuc].append(\n",
    "                    os.path.join(dir_str_or_nuc_motifs, filename_motif)\n",
    "                )\n",
    "\n",
    "str_or_nuc_to_input_or_background_to_output_paths_dict = {}\n",
    "\n",
    "with open(os.path.join(dir_user, 'Out.log'), 'w') as fw:\n",
    "    for str_or_nuc, dir_str_or_nuc_motifs, min_seq_len_str_or_nuc in zip(\n",
    "            [search_struct_motifs, search_seq_motifs],\n",
    "            [dir_struct_motifs, dir_nucleotide_motifs],\n",
    "            [MIN_LEN_SEQ_FOR_STR_MOTIFS, 3]\n",
    "    ):\n",
    "        if str_or_nuc:\n",
    "            fw.write('{} search\\n'.format(str_or_nuc))\n",
    "            fw.flush()\n",
    "\n",
    "            str_or_nuc_to_input_or_background_to_output_paths_dict[str_or_nuc] = {}\n",
    "\n",
    "            # For input and (eventually) the background\n",
    "            for path_complete_input_rna_molecules_xxx, input_or_background in zip(\n",
    "                    [path_complete_input_rna_molecules, path_complete_input_rna_molecules_background],\n",
    "                    ['input', 'background']\n",
    "            ):\n",
    "                # The background path can be empty\n",
    "                if path_complete_input_rna_molecules_xxx:\n",
    "                    str_or_nuc_to_input_or_background_to_output_paths_dict[str_or_nuc][input_or_background] = []\n",
    "\n",
    "                    for i, path_motif in enumerate(path_str_or_nuc_motif_to_search_dict[str_or_nuc]):\n",
    "                        fw.write('search on {} database completed ({} / {}) '.format(\n",
    "                            os.path.basename(path_motif), i + 1, len(path_str_or_nuc_motif_to_search_dict[str_or_nuc]))\n",
    "                        )\n",
    "                        fw.flush()\n",
    "\n",
    "                        path_str_or_nuc_search_out = os.path.join(dir_user, 'search_out.{}.txt'.format(\n",
    "                            os.path.basename(path_motif).split(\".\")[0]\n",
    "                        ))\n",
    "                        run_search(\n",
    "                            dir_base,\n",
    "                            path_motif,\n",
    "                            path_complete_input_rna_molecules_xxx,\n",
    "                            str_or_nuc == 'str',\n",
    "                            path_str_or_nuc_search_out,\n",
    "                            min_seq_len_str_or_nuc\n",
    "                        )\n",
    "                        str_or_nuc_to_input_or_background_to_output_paths_dict[str_or_nuc][\n",
    "                            input_or_background\n",
    "                        ].append(path_str_or_nuc_search_out)\n",
    "                        fw.write('---> done\\n')\n",
    "\n",
    "input_header_to_seq_and_bear_dict = {}\n",
    "with open(path_complete_input_rna_molecules) as f:\n",
    "    for line in f:\n",
    "        header = line.strip().lstrip('>')\n",
    "        sequence = f.readline().strip()\n",
    "\n",
    "        f.readline()  # Dot-bracket\n",
    "        seq_bear = f.readline().strip()\n",
    "\n",
    "        input_header_to_seq_and_bear_dict[header] = [sequence, seq_bear]\n",
    "\n",
    "str_or_nuc_to_motifs_to_seq_to_info_dict = {}\n",
    "str_or_nuc_to_motif_to_input_or_background_to_count_dict = {}\n",
    "\n",
    "seq_to_str_or_nuc_to_all_motifs_dict = {}\n",
    "\n",
    "for str_or_nuc, input_or_background_to_output_paths in str_or_nuc_to_input_or_background_to_output_paths_dict.items():\n",
    "    str_or_nuc_to_motifs_to_seq_to_info_dict[str_or_nuc] = {}\n",
    "    str_or_nuc_to_motif_to_input_or_background_to_count_dict[str_or_nuc] = {}\n",
    "\n",
    "    for input_or_background, output_path_list in input_or_background_to_output_paths.items():\n",
    "        for output_path in output_path_list:\n",
    "            with open(output_path) as f:\n",
    "                # {\"chr1:149783661-149783992(-)\": {\"ENCFF261SMW_DDX6_UTR_m2_run1.nuc.txt\": [2.7200000000000006, 11.4, 31, 12],\n",
    "                seq_to_motif_to_info_dict = json.load(f)\n",
    "\n",
    "            #               s<t s>t\n",
    "            # input         x   x\n",
    "            # background    x   x\n",
    "            for seq, motif_to_info_dict in seq_to_motif_to_info_dict.items():\n",
    "                if seq not in seq_to_str_or_nuc_to_all_motifs_dict:\n",
    "                    seq_to_str_or_nuc_to_all_motifs_dict[seq] = {}\n",
    "                if str_or_nuc not in seq_to_str_or_nuc_to_all_motifs_dict[seq]:\n",
    "                    seq_to_str_or_nuc_to_all_motifs_dict[seq][str_or_nuc] = []\n",
    "\n",
    "                for motif, (score, thresh, start, length) in motif_to_info_dict.items():\n",
    "                    if motif not in str_or_nuc_to_motif_to_input_or_background_to_count_dict[str_or_nuc]:\n",
    "                        str_or_nuc_to_motif_to_input_or_background_to_count_dict[str_or_nuc][motif] = {\n",
    "                            'input': [0, 0],\n",
    "                            'background': [0, 0]\n",
    "                        }\n",
    "\n",
    "                    if score < thresh:\n",
    "                        str_or_nuc_to_motif_to_input_or_background_to_count_dict[str_or_nuc][motif][\n",
    "                            input_or_background][0] += 1\n",
    "                    else:\n",
    "                        str_or_nuc_to_motif_to_input_or_background_to_count_dict[str_or_nuc][motif][\n",
    "                            input_or_background][1] += 1\n",
    "\n",
    "                        seq_to_str_or_nuc_to_all_motifs_dict[seq][str_or_nuc].append(motif)\n",
    "\n",
    "                        if input_or_background == 'input':\n",
    "                            if motif not in str_or_nuc_to_motifs_to_seq_to_info_dict[str_or_nuc]:\n",
    "                                str_or_nuc_to_motifs_to_seq_to_info_dict[str_or_nuc][motif] = {}\n",
    "                            str_or_nuc_to_motifs_to_seq_to_info_dict[str_or_nuc][motif][seq] = [\n",
    "                                input_header_to_seq_and_bear_dict[seq][1 if str_or_nuc == 'str' else 0][\n",
    "                                start:(start + length)],\n",
    "                                score,\n",
    "                                len(input_header_to_seq_and_bear_dict[seq][0]),\n",
    "                                start,\n",
    "                                start + length - 1,\n",
    "                                thresh\n",
    "                            ]\n",
    "\n",
    "if not is_there_a_background:\n",
    "    with open(os.path.join(dir_base, 'resources', 'summary_AutoBg.txt')) as f:\n",
    "        for line in f:\n",
    "            motif, _, minor, major = line.strip().split()  # minor (s<t) and major (s>+t)\n",
    "\n",
    "            for str_or_nuc, motif_to_input_or_background_to_count_dict in str_or_nuc_to_motif_to_input_or_background_to_count_dict.items():\n",
    "                if motif in motif_to_input_or_background_to_count_dict:\n",
    "                    str_or_nuc_to_motif_to_input_or_background_to_count_dict[str_or_nuc][motif]['background'] = [\n",
    "                        int(minor), int(major)\n",
    "                    ]\n",
    "\n",
    "# Read domain information\n",
    "motifs_to_domains_dict = {}\n",
    "for str_or_nuc, dir_str_or_nuc_motifs_domains in zip(\n",
    "        [search_struct_motifs, search_seq_motifs],\n",
    "        [dir_struct_motifs_domains, dir_nucleotide_motifs_domains],\n",
    "):\n",
    "    if str_or_nuc:\n",
    "        with open(dir_str_or_nuc_motifs_domains) as f:\n",
    "            for line in f:\n",
    "                line_split = line.strip().split('\\t')\n",
    "\n",
    "                for motif in line_split[1:]:\n",
    "                    if motif not in motifs_to_domains_dict:\n",
    "                        motifs_to_domains_dict[motif] = []\n",
    "                    motifs_to_domains_dict[motif].append(line_split[0])\n",
    "\n",
    "motif_results_dict = {}\n",
    "\n",
    "for str_or_nuc, motif_to_input_or_background_to_count_dict in str_or_nuc_to_motif_to_input_or_background_to_count_dict.items():\n",
    "    motif_results_dict[str_or_nuc] = {}\n",
    "\n",
    "    for motif, input_or_background_to_count_dict in motif_to_input_or_background_to_count_dict.items():\n",
    "        oddsratio, pvalue = stats.fisher_exact(\n",
    "            [input_or_background_to_count_dict['input'], input_or_background_to_count_dict['background']],\n",
    "            alternative='less'\n",
    "        )\n",
    "        motif_results_dict[str_or_nuc][motif] = [\n",
    "            input_or_background_to_count_dict['input'][1] / sum(input_or_background_to_count_dict['input']),\n",
    "            oddsratio, pvalue,\n",
    "            motifs_to_domains_dict[motif] if motif in motifs_to_domains_dict else []\n",
    "        ]\n",
    "\n",
    "input_str_or_nuc_to_to_output_paths_dict = {}\n",
    "for str_or_nuc, input_or_background_to_output_paths_dict in str_or_nuc_to_input_or_background_to_output_paths_dict.items():\n",
    "    input_str_or_nuc_to_to_output_paths_dict[str_or_nuc] = input_or_background_to_output_paths_dict['input']\n",
    "\n",
    "dir_user_download = os.path.join(dir_user, 'download')\n",
    "dir_user_download_motifs = os.path.join(dir_user, 'download/motifs')\n",
    "if not os.path.exists(dir_user_download_motifs):\n",
    "    os.makedirs(dir_user_download_motifs)\n",
    "\n",
    "# print(seq_to_str_or_nuc_to_all_motifs_dict)\n",
    "\n",
    "################################################\n",
    "# seq_to_str_or_nuc_to_filt_motifs_dict = {}\n",
    "seq_to_sign_motifs_dict = {}\n",
    "\n",
    "for seq, str_or_nuc_to_all_motifs_dict in seq_to_str_or_nuc_to_all_motifs_dict.items():\n",
    "    # seq_to_str_or_nuc_to_filt_motifs_dict[seq] = {\n",
    "    #    'str': [],\n",
    "    #    'nuc': []\n",
    "    # }\n",
    "    seq_to_sign_motifs_dict[seq] = []\n",
    "\n",
    "    for str_or_nuc, motif_list in str_or_nuc_to_all_motifs_dict.items():\n",
    "        for motif in motif_list:\n",
    "            if motif_results_dict[str_or_nuc][motif][0] > 0.5 and motif_results_dict[str_or_nuc][motif][2] < 0.05:\n",
    "                # seq_to_str_or_nuc_to_filt_motifs_dict[seq][str_or_nuc].append(motif)\n",
    "                seq_to_sign_motifs_dict[seq].append(motif)\n",
    "################################################\n",
    "\n",
    "for str_or_nuc, motifs_to_seq_to_info_dict in str_or_nuc_to_motifs_to_seq_to_info_dict.items():\n",
    "    for motif, seq_to_info in motifs_to_seq_to_info_dict.items():\n",
    "        if motif_results_dict[str_or_nuc][motif][2] < 0.05:\n",
    "            with open(os.path.join(dir_user_download_motifs, motif), 'w') as fw:\n",
    "                fw.write('\\t'.join(['name', 'motif', 'score', 'length', 'start', 'end', 'threshold']) + '\\n')\n",
    "\n",
    "                for seq, info_list in seq_to_info.items():\n",
    "                    fw.write('\\t'.join([seq] + [str(x) for x in info_list]) + '\\n')\n",
    "\n",
    "species_to_protein_to_link_dict = {}\n",
    "\n",
    "path_protein_links = os.path.join(dir_base, 'resources/protein_links.txt')\n",
    "with open(path_protein_links) as f:\n",
    "    f.readline()\n",
    "\n",
    "    for line in f:\n",
    "        protein_name, species, link = line.split('\\t')\n",
    "\n",
    "        if species not in species_to_protein_to_link_dict:\n",
    "            species_to_protein_to_link_dict[species] = {}\n",
    "\n",
    "        species_to_protein_to_link_dict[species][protein_name] = link.strip()\n",
    "\n",
    "reproduciblePeakFilename_to_RBP_CellLine_dict = {}\n",
    "\n",
    "path_eclip_cell_lines = os.path.join(dir_base, 'resources/eCLIP_CellLines.txt')\n",
    "with open(path_eclip_cell_lines) as f:\n",
    "    f.readline()\n",
    "\n",
    "    for line in f:\n",
    "        RBP, CellLine, ReproduciblePeakFilename = line.strip().split('\\t')\n",
    "\n",
    "        if ReproduciblePeakFilename not in reproduciblePeakFilename_to_RBP_CellLine_dict:\n",
    "            reproduciblePeakFilename_to_RBP_CellLine_dict[ReproduciblePeakFilename] = {}\n",
    "\n",
    "        reproduciblePeakFilename_to_RBP_CellLine_dict[ReproduciblePeakFilename] = [RBP, CellLine]\n",
    "\n",
    "publication_to_Link_dict = {}\n",
    "\n",
    "path_eclip_cell_lines = os.path.join(dir_base, 'resources/publications_CLIP_data.txt')\n",
    "with open(path_eclip_cell_lines) as f:\n",
    "    f.readline()\n",
    "\n",
    "    for line in f:\n",
    "        publication, link = line.strip().split('\\t')\n",
    "\n",
    "        if publication not in publication_to_Link_dict:\n",
    "            publication_to_Link_dict[publication] = {}\n",
    "\n",
    "        publication_to_Link_dict[publication] = link\n",
    "\n",
    "os.system(\"cp \" + os.path.join(dir_base, 'public/examples/README.txt') + \" \" + dir_user_download)\n",
    "\n",
    "output_generation.generate_output(\n",
    "    dir_base,\n",
    "    path_complete_input_rna_molecules,\n",
    "    os.path.join(dir_user, 'results.html'),\n",
    "    os.path.join(dir_user_download, 'tab_sequences.txt'),\n",
    "    os.path.join(dir_user_download, 'tab_enriched_motifs.txt'),\n",
    "    dir_user_download,\n",
    "    input_str_or_nuc_to_to_output_paths_dict,\n",
    "    motif_results_dict,\n",
    "    seq_to_sign_motifs_dict,\n",
    "    user_email,\n",
    "    species_to_protein_to_link_dict,\n",
    "    reproduciblePeakFilename_to_RBP_CellLine_dict,\n",
    "    publication_to_Link_dict\n",
    ")\n",
    "\n",
    "with open(os.path.join(dir_user, 'Out.log'), 'w') as fw:\n",
    "    fw.write('100')\n",
    "\n",
    "# Remove temporary files\n",
    "for path_tmp_file in [os.path.join(dir_user, x) for x in os.listdir(dir_user) if x.startswith('tmp.')]:\n",
    "    print('Remove', path_tmp_file)\n",
    "    os.remove(path_tmp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef1b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
